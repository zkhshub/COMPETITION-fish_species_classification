{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('cuda') if torch.cuda.is_available() else print('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# torch\\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\\n\\n# albumentations\\npip install -U albumentations\\n# libGL.so.1: cannot open shared object file: No such file or directory\\napt-get update && apt-get install libgl1\\n\\n# PIL\\npip install pillow\\n\\n# openCV\\npip install opencv-python\\n\\n# sklearn\\npip install scikit-learn\\n\\n# ImportError: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant'\\npip install chardet\\n\\n# numpy pandas matplolib seaborn...\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# torch\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "# albumentations\n",
    "pip install -U albumentations\n",
    "# libGL.so.1: cannot open shared object file: No such file or directory\n",
    "apt-get update && apt-get install libgl1\n",
    "\n",
    "# PIL\n",
    "pip install pillow\n",
    "\n",
    "# openCV\n",
    "pip install opencv-python\n",
    "\n",
    "# sklearn\n",
    "pip install scikit-learn\n",
    "\n",
    "# ImportError: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant'\n",
    "pip install chardet\n",
    "\n",
    "# numpy pandas matplolib seaborn...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file len\n",
      "train : 104876, test : 44947\n",
      "Copied file len\n",
      "train : 104875, test : 44946\n"
     ]
    }
   ],
   "source": [
    "cwd = \"/USER/mnc/fish_copy/data/\"\n",
    "\n",
    "train_dir = cwd + \"train/\"\n",
    "test_dir  = cwd + \"test/\"\n",
    "\n",
    "train_list = os.listdir(train_dir)\n",
    "test_list  = os.listdir(test_dir)\n",
    "\n",
    "print(\"Original file len\")\n",
    "print(\"train : 104876, test : 44947\")\n",
    "print(\"Copied file len\")\n",
    "print(f\"train : {len(train_list)}, test : {len(test_list)}\")\n",
    "\n",
    "train_list = sorted(train_list, key= lambda x: int(x[6:-4]))\n",
    "test_list  = sorted(test_list, key= lambda x: int(x[5:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ann_json    = cwd + 'labels/train.json'\n",
    "answer_json = cwd + 'labels/answer_sample.json'\n",
    "\n",
    "coco = COCO(ann_json)\n",
    "coco_answer = COCO(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category ID check\n",
    "coco.getCatIds()\n",
    "\n",
    "# find annotation ID of image_id\n",
    "coco.getAnnIds(imgIds=1)\n",
    "# find annotation ID of category_id\n",
    "coco.getAnnIds(catIds=1)\n",
    "\n",
    "# find Image ID of category_id\n",
    "coco.getImgIds(catIds=1)\n",
    "\n",
    "# Specific data of category_id\n",
    "coco.loadCats(1)\n",
    "\n",
    "# All specific annotation dict data of annotation_id\n",
    "coco.loadAnns(1)\n",
    "\n",
    "# All specific image dict data of image_id\n",
    "coco.loadImgs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category 정보 추출\n",
    "categories = coco.getCatIds()\n",
    "\n",
    "# 해당 category에 해당하는 image_id 다 찾기\n",
    "for i in categories:\n",
    "    globals()[f\"category{i}_imgid\"] = coco.getImgIds(catIds=i)\n",
    "\n",
    "# Created list category0_imgid ~ category7imgid\n",
    "\n",
    "# image_id를 이용해서 file_name찾기\n",
    "for i in categories:\n",
    "    globals()[f\"category{i}_imgname\"] = []\n",
    "    for j in eval(f\"category{i}_imgid\"):\n",
    "        eval(f\"category{i}_imgname\").append(coco.loadImgs(j)[0]['file_name'])\n",
    "\n",
    "# Created list category0_imgname ~ category7_imgname\n",
    "\n",
    "\"\"\"\n",
    "# image_id로 annotation_id 찾기\n",
    "여기서 이미지 아이디를 기반으로 어노테이션 아이디를 찾고\n",
    "\n",
    "# annotation_id로 해당 annotation정보 찾기\n",
    "찾은 어노테이션 아이디를 기반으로 bbox 정보 찾기\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category0_imgid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = [0 for i in range(len(train_list))]\n",
    "len(train_list), len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadImgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 5543,\n",
       "  'width': 640,\n",
       "  'height': 480,\n",
       "  'file_name': 'train_3865.png',\n",
       "  'license': 0,\n",
       "  'flickr_url': '',\n",
       "  'coco_url': '',\n",
       "  'date_captured': 0}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadImgs(5543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 5543,\n",
       "  'image_id': 98263,\n",
       "  'category_id': 2,\n",
       "  'segmentation': [],\n",
       "  'area': 11502.345400000006,\n",
       "  'bbox': [351.64, 305.7, 139.49, 82.46],\n",
       "  'iscrowd': 0,\n",
       "  'attributes': {'occluded': False, 'rotation': 0.0}}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadAnns(5543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files:  5561\n"
     ]
    }
   ],
   "source": [
    "whole_image_ids = coco.getImgIds()\n",
    "image_ids = []\n",
    "no_anno_ids = []\n",
    "\n",
    "# to remove not annotated image idx\n",
    "for idx in whole_image_ids:\n",
    "    annotations_ids = coco.getAnnIds(imgIds=idx, iscrowd=False)\n",
    "    if len(annotations_ids) == 0:\n",
    "        no_anno_ids.append(idx)\n",
    "    else:\n",
    "        image_ids.append(idx)\n",
    "\n",
    "\n",
    "train_files = []\n",
    "for id in image_ids:\n",
    "    train_file = coco.loadImgs(id)[0]['file_name']\n",
    "    train_files.append(train_file)\n",
    "\n",
    "print(\"train_files: \", len(train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 283, 284, 292, 297],\n",
       " ['train_0.png',\n",
       "  'train_185.png',\n",
       "  'train_186.png',\n",
       "  'train_192.png',\n",
       "  'train_194.png'],\n",
       " 99314)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids[:5], train_files[:5], len(no_anno_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5561 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/USER/mnc/fish/data/train/train_0.png\n",
      "/USER/mnc/fish/data/train_fish/train_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "output_path = '/USER/mnc/fish/data/train_fish'\n",
    "\n",
    "def load_images_from_folder(folder, train_files, output_path):\n",
    "    count = 0\n",
    "    for filename in tqdm(train_files):\n",
    "        source = os.path.join(folder, filename)\n",
    "        destination = f\"{output_path}/{filename[:-4]}.jpg\"\n",
    "        print(source)\n",
    "        print(destination)\n",
    "        break\n",
    "        \n",
    "        try:\n",
    "            shutil.copy(source, destination)\n",
    "            print(\"File copied successfully.\")\n",
    "\n",
    "        # If source and destination are same\n",
    "        except shutil.SameFileError:\n",
    "            print(\"Source and destination represents the same file.\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "load_images_from_folder(folder='/USER/mnc/fish/data/train', train_files=train_files, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.getCatIds(catNms='농어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, [37.98, 209.94, 369.19, 110.89])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category, bbox = coco.loadAnns(coco.getAnnIds(1))[0]['category_id'], coco.loadAnns(coco.getAnnIds(1))[0]['bbox']\n",
    "\n",
    "category, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "coco_class = ['농어', '베스', '숭어', '강준치', '블루길', '잉어', '붕어', '누치']\n",
    "\n",
    "for num in range(1000):\n",
    "    img = Image.open(cwd + \"train/\" + train_files[num])\n",
    "    category, bbox = coco.loadAnns(coco.getAnnIds(image_ids[num]))[0]['category_id'], coco.loadAnns(coco.getAnnIds(image_ids[num]))[0]['bbox']\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(\"root/anaconda3/envs/fish/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/NanumGothic.ttf\", 30)\n",
    "    draw.text((250, 5), coco_class[category], fill='red', font=font)\n",
    "\n",
    "\n",
    "    # COCO annotation에서 (x, y, width, height) 형태를 (x, y, x+width, y+height)로 변환\n",
    "    x, y, width, height = bbox\n",
    "    x, y, x2, y2 = x, y, x + width, y + height\n",
    "\n",
    "    # bounding box를 시각화\n",
    "    # rect = patches.Rectangle((x, y), width, height, linewidth=2, edgecolor=\"r\", facecolor=\"none\", label=f\"Category {category}\")\n",
    "    # plt.gca().add_patch(rect)\n",
    "    draw.rectangle([x, y, x2, y2], outline='red')\n",
    "\n",
    "    display(img)\n",
    "\n",
    "    # 사용자의 입력을 기다립니다.\n",
    "    user_input = input(\"Press Enter to open the next image, or 'q' to quit...\")\n",
    "\n",
    "    # 이미지를 닫습니다.\n",
    "    clear_output()\n",
    "\n",
    "    # 사용자가 'q'를 누르면 루프를 종료합니다.\n",
    "    if user_input.lower() == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishDataLoader(Dataset):\n",
    "    def __init__(self, root_dir=\"/USER/mnc/fish/data/\", train_list=None, train_label=None, train=True, augmentations=None):\n",
    "        super().__init__()\n",
    "        # self.train = train\n",
    "        self.transforms    = T.ToTensor()\n",
    "        self.root_dir      = root_dir\n",
    "        self.train         = True if train else False\n",
    "        self.leaf_data_dir = 'train/' if train else 'test/'\n",
    "        self.json_name     = 'train.json' if train else None\n",
    "        \n",
    "        self.train_list  = train_list\n",
    "        self.train_label = train_label\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.root_dir + self.leaf_data_dir + self.train_list[index]).convert('RGB')\n",
    "        img = self.transforms(img)\n",
    "        if self.train:\n",
    "            label = self.train_label[index]\n",
    "            label = torch.tensor(label, dtype=torch.int8)\n",
    "        else:\n",
    "            label = None\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = FishDataLoader(train_list=train_list, train_label=train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2588, 0.2588, 0.2784,  ..., 0.3373, 0.3373, 0.3373],\n",
       "          [0.2588, 0.2588, 0.2784,  ..., 0.3333, 0.3333, 0.3333],\n",
       "          [0.2510, 0.2510, 0.2941,  ..., 0.3333, 0.3333, 0.3333],\n",
       "          ...,\n",
       "          [0.0863, 0.0863, 0.0863,  ..., 0.0235, 0.0157, 0.0235],\n",
       "          [0.0902, 0.0902, 0.0902,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0902, 0.0902, 0.0902,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.2863, 0.2863, 0.2745,  ..., 0.3451, 0.3451, 0.3451],\n",
       "          [0.2863, 0.2863, 0.2745,  ..., 0.3412, 0.3412, 0.3412],\n",
       "          [0.2902, 0.2902, 0.2627,  ..., 0.3412, 0.3412, 0.3412],\n",
       "          ...,\n",
       "          [0.0941, 0.0941, 0.0941,  ..., 0.0314, 0.0235, 0.0314],\n",
       "          [0.0980, 0.0980, 0.0980,  ..., 0.0039, 0.0000, 0.0039],\n",
       "          [0.0980, 0.0980, 0.0980,  ..., 0.0000, 0.0000, 0.0039]],\n",
       " \n",
       "         [[0.2667, 0.2667, 0.2863,  ..., 0.3333, 0.3333, 0.3333],\n",
       "          [0.2667, 0.2667, 0.2863,  ..., 0.3294, 0.3294, 0.3294],\n",
       "          [0.2588, 0.2588, 0.2863,  ..., 0.3294, 0.3294, 0.3294],\n",
       "          ...,\n",
       "          [0.0824, 0.0824, 0.0824,  ..., 0.0196, 0.0118, 0.0196],\n",
       "          [0.0863, 0.0863, 0.0863,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0863, 0.0863, 0.0863,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(0, dtype=torch.int8))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
